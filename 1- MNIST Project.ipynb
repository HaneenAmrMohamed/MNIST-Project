{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\data science-anaconda\\envs\\py3-TF2.0\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\User\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/2 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/3 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/4 [00:06<?, ? url/s]\n",
      "Dl Size...:   0%|                                                                              | 0/9 [00:06<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/4 [00:06<?, ? url/s]\n",
      "Dl Size...:   0%|                                                                              | 0/9 [00:06<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/4 [00:06<?, ? url/s]\n",
      "Dl Size...:   0%|                                                                              | 0/9 [00:06<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/4 [00:06<?, ? url/s]\n",
      "Dl Size...:   0%|                                                                             | 0/10 [00:06<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|████████████████▎                                                | 1/4 [00:06<00:18,  6.30s/ url]\n",
      "Dl Size...:   0%|                                                                             | 0/10 [00:06<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|████████████████▎                                                | 1/4 [00:06<00:18,  6.30s/ url]\n",
      "Dl Size...:   0%|                                                                             | 0/10 [00:06<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:   0%|                                                                | 0/1 [00:06<?, ? file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|████████████████▎                                                | 1/4 [00:06<00:18,  6.30s/ url]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|                                                                             | 0/10 [00:06<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:15<00:15,  7.72s/ url]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|                                                                             | 0/10 [00:15<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:15<00:15,  7.72s/ url]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|                                                                             | 0/10 [00:15<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:  50%|████████████████████████████                            | 1/2 [00:15<00:06,  6.32s/ file]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:15<00:15,  7.72s/ url]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|                                                                             | 0/10 [00:15<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.74s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [01:59<00:15,  7.72s/ url]\u001b[A\n",
      "Dl Size...:  10%|██████▊                                                             | 1/10 [01:59<17:52, 119.18s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [02:07<00:55, 55.68s/ url]\u001b[A\u001b[A\n",
      "Dl Size...:  10%|██████▊                                                             | 1/10 [02:07<17:52, 119.18s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [02:07<00:55, 55.68s/ url]\u001b[A\u001b[A\n",
      "Dl Size...:  10%|██████▊                                                             | 1/10 [02:07<17:52, 119.18s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...:  67%|█████████████████████████████████████▎                  | 2/3 [02:07<00:07,  7.74s/ file]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [02:07<00:55, 55.68s/ url]\u001b[A\u001b[A\n",
      "Dl Size...:  10%|██████▊                                                             | 1/10 [02:07<17:52, 119.18s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 3/3 [02:07<00:00, 55.71s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [03:11<00:55, 55.68s/ url]\u001b[A\n",
      "Dl Size...:  20%|█████████████▊                                                       | 2/10 [03:11<12:12, 91.60s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 3/3 [03:11<00:00, 55.71s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [03:21<00:55, 55.68s/ url]\u001b[A\n",
      "Dl Size...:  30%|████████████████████▋                                                | 3/10 [03:21<06:21, 54.47s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 3/3 [03:21<00:00, 55.71s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [03:39<00:55, 55.68s/ url]\u001b[A\n",
      "Dl Size...:  40%|███████████████████████████▌                                         | 4/10 [03:39<03:58, 39.79s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 3/3 [03:39<00:00, 55.71s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [03:42<00:55, 55.68s/ url]\u001b[A\n",
      "Dl Size...:  50%|██████████████████████████████████▌                                  | 5/10 [03:42<02:14, 26.86s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 3/3 [03:42<00:00, 55.71s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [03:54<00:55, 55.68s/ url]\u001b[A\n",
      "Dl Size...:  60%|█████████████████████████████████████████▍                           | 6/10 [03:54<01:26, 21.73s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 3/3 [03:54<00:00, 55.71s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [04:00<00:55, 55.68s/ url]\u001b[A\n",
      "Dl Size...:  70%|████████████████████████████████████████████████▎                    | 7/10 [04:00<00:49, 16.49s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 3/3 [04:00<00:00, 55.71s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [04:03<00:55, 55.68s/ url]\u001b[A\n",
      "Dl Size...:  80%|███████████████████████████████████████████████████████▏             | 8/10 [04:03<00:24, 12.12s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [04:03<00:55, 55.68s/ url]\u001b[A\u001b[A\n",
      "Dl Size...:  90%|██████████████████████████████████████████████████████████████       | 9/10 [04:03<00:12, 12.12s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 3/3 [04:03<00:00, 55.71s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [04:07<00:55, 55.68s/ url]\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [04:07<00:00,  7.41s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|█████████████████████████████████████████████████████████████████| 4/4 [04:08<00:00, 81.55s/ url]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [04:08<00:00,  7.41s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|█████████████████████████████████████████████████████████████████| 4/4 [04:09<00:00, 81.55s/ url]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [04:09<00:00,  7.41s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...:  75%|██████████████████████████████████████████              | 3/4 [04:09<00:55, 55.71s/ file]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|█████████████████████████████████████████████████████████████████| 4/4 [04:09<00:00, 81.55s/ url]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [04:09<00:00,  7.41s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 4/4 [04:09<00:00, 62.35s/ file]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [04:09<00:00, 24.94s/ MiB]\n",
      "Dl Completed...: 100%|█████████████████████████████████████████████████████████████████| 4/4 [04:09<00:00, 62.35s/ url]\n",
      "Generating splits...:   0%|                                                                 | 0/2 [00:00<?, ? splits/s]\n",
      "Generating train examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating train examples...: 1428 examples [00:01, 1412.77 examples/s]\u001b[A\n",
      "Generating train examples...: 3137 examples [00:02, 1586.05 examples/s]\u001b[A\n",
      "Generating train examples...: 4845 examples [00:03, 1641.16 examples/s]\u001b[A\n",
      "Generating train examples...: 6790 examples [00:04, 1752.81 examples/s]\u001b[A\n",
      "Generating train examples...: 8543 examples [00:05, 1739.46 examples/s]\u001b[A\n",
      "Generating train examples...: 10283 examples [00:06, 1689.57 examples/s]\u001b[A\n",
      "Generating train examples...: 12186 examples [00:07, 1757.18 examples/s]\u001b[A\n",
      "Generating train examples...: 13947 examples [00:08, 1706.95 examples/s]\u001b[A\n",
      "Generating train examples...: 15983 examples [00:09, 1806.44 examples/s]\u001b[A\n",
      "Generating train examples...: 18027 examples [00:10, 1870.52 examples/s]\u001b[A\n",
      "Generating train examples...: 20115 examples [00:11, 1930.09 examples/s]\u001b[A\n",
      "Generating train examples...: 22190 examples [00:12, 1973.19 examples/s]\u001b[A\n",
      "Generating train examples...: 24434 examples [00:13, 2053.73 examples/s]\u001b[A\n",
      "Generating train examples...: 26689 examples [00:14, 2113.93 examples/s]\u001b[A\n",
      "Generating train examples...: 28906 examples [00:15, 2144.23 examples/s]\u001b[A\n",
      "Generating train examples...: 31134 examples [00:16, 2169.33 examples/s]\u001b[A\n",
      "Generating train examples...: 33330 examples [00:17, 2172.51 examples/s]\u001b[A\n",
      "Generating train examples...: 35504 examples [00:18, 1937.92 examples/s]\u001b[A\n",
      "Generating train examples...: 37490 examples [00:19, 1893.24 examples/s]\u001b[A\n",
      "Generating train examples...: 39417 examples [00:20, 1882.04 examples/s]\u001b[A\n",
      "Generating train examples...: 41333 examples [00:21, 1886.51 examples/s]\u001b[A\n",
      "Generating train examples...: 43236 examples [00:22, 1836.98 examples/s]\u001b[A\n",
      "Generating train examples...: 45268 examples [00:23, 1888.40 examples/s]\u001b[A\n",
      "Generating train examples...: 47168 examples [00:24, 1878.93 examples/s]\u001b[A\n",
      "Generating train examples...: 49055 examples [00:26, 1850.18 examples/s]\u001b[A\n",
      "Generating train examples...: 50911 examples [00:27, 1827.38 examples/s]\u001b[A\n",
      "Generating train examples...: 52743 examples [00:28, 1777.76 examples/s]\u001b[A\n",
      "Generating train examples...: 54572 examples [00:29, 1792.32 examples/s]\u001b[A\n",
      "Generating train examples...: 56368 examples [00:30, 1726.70 examples/s]\u001b[A\n",
      "Generating train examples...: 58178 examples [00:31, 1749.55 examples/s]\u001b[A\n",
      "Generating train examples...: 59933 examples [00:32, 1697.43 examples/s]\u001b[A\n",
      "                                                                        \u001b[A\n",
      "Shuffling C:\\Users\\User\\tensorflow_datasets\\mnist\\incomplete.GQYM5I_3.0.1\\mnist-train.tfrecord*...:   0%| | 0/60000 [00\u001b[A\n",
      "Generating splits...:  50%|████████████████████████████▌                            | 1/2 [00:33<00:33, 33.28s/ splits]\u001b[A\n",
      "Generating test examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating test examples...: 1678 examples [00:01, 1657.17 examples/s]\u001b[A\n",
      "Generating test examples...: 3665 examples [00:02, 1849.56 examples/s]\u001b[A\n",
      "Generating test examples...: 5742 examples [00:03, 1941.57 examples/s]\u001b[A\n",
      "Generating test examples...: 7703 examples [00:04, 1947.75 examples/s]\u001b[A\n",
      "Generating test examples...: 9651 examples [00:05, 1826.94 examples/s]\u001b[A\n",
      "                                                                      \u001b[A\n",
      "Shuffling C:\\Users\\User\\tensorflow_datasets\\mnist\\incomplete.GQYM5I_3.0.1\\mnist-test.tfrecord*...:   0%| | 0/10000 [00:\u001b[A\n",
      "                                                                                                                       \u001b[A\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to C:\\Users\\User\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
    "# with_info=True: provides us with a tuple-structure dataset for inputs and targets.\n",
    "\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']\n",
    "\n",
    "\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)\n",
    "\n",
    "\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.\n",
    "    # dividing each element by 255 to get the desired result -> all elements will be between 0 and 1 \n",
    "    return image, label\n",
    "\n",
    "\n",
    "scaled_train_and_validation_data = mnist_train.map(scale)\n",
    "\n",
    "\n",
    "test_data = mnist_test.map(scale)\n",
    "\n",
    "\n",
    "# shuffling the data\n",
    "BUFFER_SIZE = 10000\n",
    "# while dealing with enormous datasets, we can't shuffle the whole dataset in one go\n",
    "# so instead TF only stores BUFFER_SIZE samples in memory at a time and shuffles them\n",
    "\n",
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "\n",
    "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
    "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "# while training data, it would be easier to iterate over the different batches\n",
    "\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "\n",
    "validation_inputs, validation_targets = next(iter(validation_data)) # takes next batch (it is the only batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 50\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # each observation is 28x28x1 pixels, therefore it is a tensor of rank 3\n",
    "    # Flatten: allows us to create a feed forward neural network\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "    \n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\n",
    "\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax') # output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 2s - loss: 0.4067 - accuracy: 0.8829 - val_loss: 0.2036 - val_accuracy: 0.9373 - 2s/epoch - 4ms/step\n",
      "Epoch 2/5\n",
      "540/540 - 2s - loss: 0.1804 - accuracy: 0.9469 - val_loss: 0.1503 - val_accuracy: 0.9560 - 2s/epoch - 3ms/step\n",
      "Epoch 3/5\n",
      "540/540 - 2s - loss: 0.1370 - accuracy: 0.9596 - val_loss: 0.1224 - val_accuracy: 0.9653 - 2s/epoch - 3ms/step\n",
      "Epoch 4/5\n",
      "540/540 - 2s - loss: 0.1108 - accuracy: 0.9667 - val_loss: 0.1236 - val_accuracy: 0.9645 - 2s/epoch - 3ms/step\n",
      "Epoch 5/5\n",
      "540/540 - 2s - loss: 0.0937 - accuracy: 0.9716 - val_loss: 0.0969 - val_accuracy: 0.9720 - 2s/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c5eb1b1630>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "\n",
    "model.fit(train_data, epochs=NUM_EPOCHS, validation_data=(validation_inputs, validation_targets), verbose =2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 1s 1s/step - loss: 0.0897 - accuracy: 0.97 - 1s 1s/step - loss: 0.0897 - accuracy: 0.9728"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow)",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
